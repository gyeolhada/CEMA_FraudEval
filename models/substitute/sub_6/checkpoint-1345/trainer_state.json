{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 1345,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.18587360594795538,
      "grad_norm": 6.87352991104126,
      "learning_rate": 2.895167286245353e-05,
      "loss": 1.1297,
      "step": 50
    },
    {
      "epoch": 0.37174721189591076,
      "grad_norm": 3.9238357543945312,
      "learning_rate": 2.78364312267658e-05,
      "loss": 0.7241,
      "step": 100
    },
    {
      "epoch": 0.5576208178438662,
      "grad_norm": 5.508815288543701,
      "learning_rate": 2.674349442379182e-05,
      "loss": 0.606,
      "step": 150
    },
    {
      "epoch": 0.7434944237918215,
      "grad_norm": 6.047865390777588,
      "learning_rate": 2.5628252788104088e-05,
      "loss": 0.5852,
      "step": 200
    },
    {
      "epoch": 0.929368029739777,
      "grad_norm": 5.668423175811768,
      "learning_rate": 2.451301115241636e-05,
      "loss": 0.5769,
      "step": 250
    },
    {
      "epoch": 1.1152416356877324,
      "grad_norm": 6.096644401550293,
      "learning_rate": 2.3397769516728628e-05,
      "loss": 0.556,
      "step": 300
    },
    {
      "epoch": 1.3011152416356877,
      "grad_norm": 3.1075210571289062,
      "learning_rate": 2.2282527881040893e-05,
      "loss": 0.5602,
      "step": 350
    },
    {
      "epoch": 1.486988847583643,
      "grad_norm": 5.01204776763916,
      "learning_rate": 2.116728624535316e-05,
      "loss": 0.5268,
      "step": 400
    },
    {
      "epoch": 1.6728624535315983,
      "grad_norm": 16.22187042236328,
      "learning_rate": 2.005204460966543e-05,
      "loss": 0.3817,
      "step": 450
    },
    {
      "epoch": 1.858736059479554,
      "grad_norm": 0.35582834482192993,
      "learning_rate": 1.8936802973977697e-05,
      "loss": 0.3654,
      "step": 500
    },
    {
      "epoch": 2.0446096654275094,
      "grad_norm": 1.5706028938293457,
      "learning_rate": 1.7821561338289962e-05,
      "loss": 0.3521,
      "step": 550
    },
    {
      "epoch": 2.2304832713754648,
      "grad_norm": 0.7520604729652405,
      "learning_rate": 1.670631970260223e-05,
      "loss": 0.426,
      "step": 600
    },
    {
      "epoch": 2.41635687732342,
      "grad_norm": 22.696548461914062,
      "learning_rate": 1.55910780669145e-05,
      "loss": 0.2852,
      "step": 650
    },
    {
      "epoch": 2.6022304832713754,
      "grad_norm": 45.4254264831543,
      "learning_rate": 1.4475836431226765e-05,
      "loss": 0.3902,
      "step": 700
    },
    {
      "epoch": 2.7881040892193307,
      "grad_norm": 10.695228576660156,
      "learning_rate": 1.3360594795539035e-05,
      "loss": 0.3573,
      "step": 750
    },
    {
      "epoch": 2.973977695167286,
      "grad_norm": 7.574291229248047,
      "learning_rate": 1.2267657992565056e-05,
      "loss": 0.2602,
      "step": 800
    },
    {
      "epoch": 3.159851301115242,
      "grad_norm": 46.597164154052734,
      "learning_rate": 1.1152416356877323e-05,
      "loss": 0.2448,
      "step": 850
    },
    {
      "epoch": 3.345724907063197,
      "grad_norm": 26.109718322753906,
      "learning_rate": 1.0037174721189593e-05,
      "loss": 0.2546,
      "step": 900
    },
    {
      "epoch": 3.5315985130111525,
      "grad_norm": 0.4201143980026245,
      "learning_rate": 8.921933085501859e-06,
      "loss": 0.2337,
      "step": 950
    },
    {
      "epoch": 3.717472118959108,
      "grad_norm": 14.898733139038086,
      "learning_rate": 7.806691449814127e-06,
      "loss": 0.2108,
      "step": 1000
    },
    {
      "epoch": 3.903345724907063,
      "grad_norm": 18.950897216796875,
      "learning_rate": 6.691449814126394e-06,
      "loss": 0.1917,
      "step": 1050
    },
    {
      "epoch": 4.089219330855019,
      "grad_norm": 18.084941864013672,
      "learning_rate": 5.5985130111524165e-06,
      "loss": 0.2064,
      "step": 1100
    },
    {
      "epoch": 4.275092936802974,
      "grad_norm": 24.679244995117188,
      "learning_rate": 4.483271375464684e-06,
      "loss": 0.1985,
      "step": 1150
    },
    {
      "epoch": 4.4609665427509295,
      "grad_norm": 4.470995903015137,
      "learning_rate": 3.3680297397769517e-06,
      "loss": 0.1489,
      "step": 1200
    },
    {
      "epoch": 4.646840148698884,
      "grad_norm": 0.1471843272447586,
      "learning_rate": 2.2527881040892196e-06,
      "loss": 0.1711,
      "step": 1250
    },
    {
      "epoch": 4.83271375464684,
      "grad_norm": 72.9489974975586,
      "learning_rate": 1.137546468401487e-06,
      "loss": 0.1388,
      "step": 1300
    }
  ],
  "logging_steps": 50,
  "max_steps": 1345,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1412931739115520.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
